<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Interpret Map â€“ ArcGIS Pro AI Toolbox</title>
  <link rel="stylesheet" href="../style.css">
  <script src="../navigation.js"></script>
</head>
<body class="tool-doc">
  <div class="content">
    <h1>Interpret Map</h1>
    <p>Interpret Map analyzes the active ArcGIS Pro map view using both a rendered screenshot and simplified spatial context from visible layers. The tool summarizes what the map communicates at the current scale, verifies visible patterns against data, and flags potential misalignment between symbology and data.</p>

    <h2>Usage</h2>
    <ol>
      <li>Open ArcGIS Pro, navigate to the extent and scale you want interpreted, and ensure the layers you care about are visible.</li>
      <li>Open the <strong>Interpret Map</strong> tool.</li>
      <li>Keep <strong>Include Map Screenshot</strong> enabled to send the rendered view to the AI (recommended for providers that support images).</li>
      <li>Optionally adjust <strong>Max Features Per Layer</strong> to control how many visible features (default 50) are summarized per layer.</li>
      <li>Click <strong>Run</strong>. The interpretation is returned in the tool messages.</li>
    </ol>

    <h2>Parameters</h2>
    <table>
      <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
      <tr><td>Source</td><td>String (Choice)</td><td>Yes</td><td class="param-desc">AI provider to use. Default: <strong>OpenRouter</strong>. Options: OpenRouter, OpenAI, Azure OpenAI, Claude, DeepSeek, Local LLM.</td></tr>
      <tr><td>Model</td><td>String</td><td>No</td><td class="param-desc">AI model for the selected provider.</td></tr>
      <tr><td>Endpoint</td><td>String</td><td>No</td><td class="param-desc">Custom endpoint URL for Azure or local models.</td></tr>
      <tr><td>Deployment Name</td><td>String</td><td>No</td><td class="param-desc">Deployment name for Azure OpenAI.</td></tr>
      <tr><td>Max Features Per Layer</td><td>Long</td><td>No</td><td class="param-desc">Maximum number of visible features per layer to include in the GeoJSON-like context (default: 50). Geometry is simplified to keep prompts small.</td></tr>
      <tr><td>Include Map Screenshot</td><td>Boolean</td><td>No</td><td class="param-desc">Capture and send a PNG of the active map view to the AI (recommended for OpenRouter, OpenAI, and Azure OpenAI models that support images).</td></tr>
    </table>

    <h2>What gets sent to the AI</h2>
    <ul>
      <li>A screenshot of the active view (if enabled).</li>
      <li>Map metadata: name, spatial reference, visible layer count.</li>
      <li>View metadata: scale and extent.</li>
      <li>Visible feature layers: renderer type, geometry type, representative attributes, and up to the configured number of simplified features intersecting the view.</li>
    </ul>

    <h2>Output</h2>
    <p>The response is structured into Interpretation, Verified Observations, Visual vs Data Notes, Confidence Notes, and One Suggested Next Step. Visual inferences are distinguished from data-backed findings.</p>

    <h2>Data Privacy Caution</h2>
    <p class="caution">
      <strong>Important:</strong> This tool sends map imagery and summarized vector context to the AI provider you select.
      Confirm that sharing this content complies with your organization&rsquo;s policies before running the tool, especially when using cloud providers.
    </p>
  </div>
</body>
</html>
